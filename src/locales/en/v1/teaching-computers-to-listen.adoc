[[ch_22]]
== Teaching Computers to Listen
:nofooter:

Up until now, you have been combining audio clips and effects to create music. What if you could get the computer to listen to parts of your composition and change the music based on how it sounds?

In this chapter we will learn about some ways to use EarSketch's `analyze()` function. We will then use the function to control parts of our music.

[[musicinformationretrieval]]
=== Music Information Retrieval

Using a computer to analyze music is part of an area of music technology called *Music Information Retrieval* (MIR). MIR is widely used in the music technology industry. MIR allows you to do things such as detect a piece of music's genre, or identify a song by humming it into your phone. In EarSketch we can analyze music and determine the volume or the brightness of a sound.

[[analysisfeatures]]
=== Analysis Features
Every sound can be analyzed in terms of its *features*. Features are the ways a computer understands sounds. The `analyze()` function allows you to find the volume of the sound with RMS_AMPLITUDE. `analyze()`  also lets you work out how bright or dark a sound is with SPECTRAL_CENTROID. You can think of this as the amount of high sounds (bright) or low sounds (dark). More information on SPECTRAL_CENTROID and RMS_AMPLITUDE is available in the Reference Section.

Let's start by using `analyze()` with RMS_AMPLITUDE. If we want to analyze a clip with RMS Amplitude, we write: `analyze(clip,RMS_AMPLITUDE)`. This returns values between 0 and 1, 0 being the softest and 1 being loudest. In the example below, we do this and then print the value that `analyze()` returns:

[role="curriculum-python"]
[source,python]
----
# Analyze: Using analyze() to get the RMS_Amplitude of a clip

# Setup
from earsketch import *
setTempo(120)

# Analysis
clip = YG_TECHNO_ELECTRIC_PIANO_2
analysisValue = analyze(clip, RMS_AMPLITUDE)
print(analysisValue)
----



[role="curriculum-javascript"]
[source,javascript]
----
// Analyze: Using analyze() to get the RMS_Amplitude of a clip

// Setup
setTempo(120);

// Analysis
var clip = YG_TECHNO_ELECTRIC_PIANO_2;
var analysisValue = analyze(clip, RMS_AMPLITUDE);
println(analysisValue);
----
In the above example try changing the variable clip from YG_TECHNO_ELECTRIC_PIANO_2 to see what amplitude you get with different sounds.

The code below analyzes the RMS amplitude (volume) of an audio clip. It then adds the clip to a track if its result is greater than a certain amount (set by threshold). The  `analyze()` function takes as its parameters an audio clip and an analysis feature, to get the average volume of the clip.

The `if` statement tests to see if the volume of the audio clip is larger than the a value (our variable, rmsThreshold). If it is larger, the audio clip is added to track 1 from measures 1-3. Try changing the value of rmsThreshold so that the clip is added to the track. 0.2 should work.


[role="curriculum-python"]
[source,python]
----
# RMS Threshold: Adds media to the DAW for large values of RMS amplitude
# By default, nothing is added: you have to change the rmsThreshold.

# Setup
from earsketch import *
setTempo(120)

# Music
# Choose the audio clip to use
clipToAnalyze = HIPHOP_TRAPHOP_BEAT_001
# Define the feature to analyze
analysisMethod = RMS_AMPLITUDE
# Define the minimum RMS amplitude necessary for the clip to be added to track 1
rmsThreshold = 0.5

# Define the starting and ending measures
start = 1
end = 3

# Analyze the RMS amplitude of the entire audio clip, and print the value to the console
rmsAmplitude = analyze(clipToAnalyze, analysisMethod)
print(rmsAmplitude)

# Set up conditional statement to add clip to track 1 only if its RMS amplitude is greater than the threshold value
if rmsAmplitude >= rmsThreshold:
    # Insert clip on track 1
    fitMedia(clipToAnalyze, 1, start, end)
----



[role="curriculum-javascript"]
[source,javascript]
----
// RMS Threshold: Adds media to the DAW for large values of RMS amplitude
// By default, nothing is added: you have to change the rmsThreshold.

// Setup
setTempo(120);

// Music
// Choose the audio clip to use
var clipToAnalyze = HIPHOP_TRAPHOP_BEAT_001;
// Define the feature to analyze
var analysisMethod = RMS_AMPLITUDE;
// Define the minimum RMS amplitude necessary for the clip to be added to track 1
var rmsThreshold = 0.5;

// Define the starting and ending measures
var start = 1;
var end = 3;

// Analyze the RMS amplitude of the entire audio clip, and print the value to the console
var rmsAmplitude = analyze(clipToAnalyze, analysisMethod);
println(rmsAmplitude);

// Set up conditional statement to add clip to track 1 only if its RMS amplitude is greater than the threshold value
if (rmsAmplitude >= rmsThreshold) {
    // Insert clip on track 1
    fitMedia(clipToAnalyze, 1, start, end);
}
----


To make the results of the analysis useful the computer must be able to change its output. You can use conditional statements to make decisions based on the values of various features.

Try running the following code. It compares the RMS amplitude of two clips at different points in time, playing the louder clip and muting the quieter clip.

This code uses a method called `analyzeTrackForTime()` to analyze the audio clip. This function is similar to `analyze()` but it also allows you to choose what part of a clip to analyze. The function has four parameters: the track number, the feature to be analyzed, and the starting and ending locations for the analysis. The function returns a number between 0 and 1, representing the average value of the feature between the chosen starting and ending point.

[role="curriculum-python"]
[source,python]
----
# Auto-Volume: Comparing RMS amplitudes
# We compare the RMS amplitude of two samples at different points in time, and adjust their respective volumes based on this.

# Setup
from earsketch import *
setTempo(120)

# Music
sound1 = ELECTRO_DRUM_MAIN_BEAT_001
sound2 = ELECTRO_DRUM_MAIN_BEAT_002
analysisMethod = RMS_AMPLITUDE
hop = 0.0625  # analyze in 1/16th note chunks
start = 1
end = 3.0

fitMedia(sound1, 1, start, end)
fitMedia(sound2, 2, start, end)

position = 1
while position < end:
    # analyze tracks at current time
    feature1 = analyzeTrackForTime(1, analysisMethod, position, position + hop)
    feature2 = analyzeTrackForTime(2, analysisMethod, position, position + hop)
    # mute the track with lower RMS value
    if feature1 > feature2:
        setEffect(1, VOLUME, GAIN, 0, position, 0, position + hop)
        setEffect(2, VOLUME, GAIN, -60, position, -60, position + hop)
    else:
        setEffect(1, VOLUME, GAIN, -60, position, -60, position + hop)
        setEffect(2, VOLUME, GAIN, 0, position, 0, position + hop)
    # increment the counter (move forward in time by the hop amount)
    position = position + hop
----


[role="curriculum-javascript"]
[source,javascript]
----
// Auto-Volume: Comparing RMS amplitudes
// We compare the RMS amplitude of two samples at different points in time, and adjust their respective volumes based on this.

// Setup
setTempo(120);

// Music
var sound1 = ELECTRO_DRUM_MAIN_BEAT_001;
var sound2 = ELECTRO_DRUM_MAIN_BEAT_002;
var analysisMethod = RMS_AMPLITUDE;
var hop = 0.0625; // analyze in 1/16th note chunks
var start = 1;
var end = 3;

fitMedia(sound1, 1, start, end);
fitMedia(sound2, 2, start, end);

var position = 1;
while (position < end) {
    // analyze tracks at current time
    var feature1 = analyzeTrackForTime(1, analysisMethod, position, position + hop);
    var feature2 = analyzeTrackForTime(2, analysisMethod, position, position + hop);
    // mute the track with lower RMS value
    if (feature1 > feature2) {
        setEffect(1, VOLUME, GAIN, 0, position, 0, position + hop);
        setEffect(2, VOLUME, GAIN, -60, position, -60, position + hop);
    } else {
        setEffect(1, VOLUME, GAIN, -60, position, -60, position + hop);
        setEffect(2, VOLUME, GAIN, 0, position, 0, position + hop);
    }
    // increment the counter (move forward in time by the hop amount)
    position = position + hop;
}
----

The *while loop* steps through each 1/16th note section of an audio clip. *While loops* enable us to execute a code block repeatedly while a condition is True. This allows our code to loop potentially forever and never stop. To make it stop the code block changes the variable used in the condition at some point.

Hop represents the distance between each part of the track that is analyzed. In this example the `hop` variable is defined as 0.0625, which is the same as a  1/16 note. The `position` variable is changed each time by adding `hop`. We then use a conditional (if and then else) to check if the volume of track 1 at each location is greater than the volume of track 2 at each location. The track with the greater volume has its volume at the current location set to 0dB using setEffect, and the track with the lesser volume is set to -60dB.


[[booleanoperators]]
=== Boolean Operators

Suppose we want to add a clip to the DAW if both the spectral centroid (brightness/darkness) AND the RMS amplitude (volume) are above a certain amount. How can we check for two conditions together?

[role="curriculum-javascript"]
You'll remember we learned about *Boolean operators* (a.k.a. logical operators) in <<console-input-and-conditionals#>>. They allow us to combine conditions; in this case we are using the *AND* operator:

[role="curriculum-python"]
You'll remember we learned about *Boolean operators* (a.k.a. logical operators) in <<console-input-and-conditionals#>>. They allow us to combine conditions; in this case we are using the *AND* operator:



[role="curriculum-python"]
[source,python]
----
# Boolean AND: Using "and" to make a condition out of two conditions

# Setup
from earsketch import *
setTempo(120)

# Choose clip to analyze
clipToAnalyze = EIGHT_BIT_ATARI_LEAD_012

# Analyze for Spectral Centroid and RMS
spectralCentroid = analyze(clipToAnalyze, SPECTRAL_CENTROID)
rms = analyze(clipToAnalyze, RMS_AMPLITUDE)

# Set the threshold
threshold = 0.1

if (spectralCentroid > threshold) and (rms > threshold):
    fitMedia(DUBSTEP_LEAD_006, 1, 1, 4)
----



[role="curriculum-javascript"]
[source,javascript]
----
// Boolean AND: Using "and" to make a condition out of two conditions

// Setup
setTempo(120);

// Choose clip to analyze
var clipToAnalyze = EIGHT_BIT_ATARI_LEAD_012;

// Analyze for Spectral Centroid and RMS
var spectralCentroid = analyze(clipToAnalyze, SPECTRAL_CENTROID);
var rms = analyze(clipToAnalyze, RMS_AMPLITUDE);

// Set the threshold
var threshold = 0.1;

if ((spectralCentroid > threshold) && (rms > threshold)) {
    fitMedia(DUBSTEP_LEAD_006, 1, 1, 4);
}
----

[role="curriculum-python"]
Let's use both features to determine whether to add clips to the DAW. Below, we choose clips to add to a track based on their analysis values. Each clip in the list is analyzed for both spectral centroid and RMS amplitude values.

[role="curriculum-javascript"]
Let's use both features to determine whether to add clips to the DAW. Below, we choose clips to add to a track based on their analysis values. Each clip in the array is analyzed for both spectral centroid and RMS amplitude values.

[role="curriculum-python"]
This example includes much of what you've learned in EarSketch. When looking at a longer script like this, start by getting a sense of the big picture. For example, you can see that there are 4 functions, 2 of which define music sections: `sectionA` and `sectionB`. Near the bottom, we call these section functions to add music to the DAW, in A-A-B-A form. The 2 other functions are "helpers" that are used inside of the section functions: `fillClipList` and `chooseClip`. The function names will often give you big clues about the overall structure!

[role="curriculum-javascript"]
This example includes much of what you've learned in EarSketch. When looking at a longer piece of code like this, start by getting a sense of the big picture. For example, you can see that there are 4 functions, 2 of which define music sections: `sectionA` and `sectionB`. Near the bottom, we call these section functions to add music to the DAW, in A-A-B-A form. The 2 other functions are "helpers" that are used inside of the section functions: `fillClipArr` and `chooseClip`. The function names will often give you big clues about the overall structure!

[role="curriculum-python"]
When each section is called, it starts by calling `fillClipList` 3 times to get a list of random clips for drums, bass, and lead. Then, the section calls `chooseClip` to pick a single clip from the random list. It chooses a clip by using Boolean operators (we'll look at this process in more detail shortly), one for each instrument. We then add these clips to the DAW with `fitMedia`. Notice that `sectionA` repeats this process, by picking clips again and adding them to the DAW; `sectionB` only does this once.

[role="curriculum-javascript"]
When each section is called, it starts by calling `fillClipArr` 3 times to get an array of random clips for drums, bass, and lead. Then, the section calls `chooseClip` to pick a single clip from the random array. It chooses a clip by using  operators (we'll look at this process in more detail shortly), one for each instrument. We then add these clips to the DAW with `fitMedia`. Notice that `sectionA` repeats this process, by picking clips again and adding them to the DAW; `sectionB` only does this once.

[role="curriculum-python"]
With `fillClipList` we pass it a folder name, and it uses a while loop to select random clips from this folder. These clips are then added to the end of the `clipList` until there are 6 clips in our list. We return `clipList` to the calling section.

[role="curriculum-javascript"]
With `fillClipArr` we pass it a folder name, and it uses a while loop to select random clips from this folder. These clips are then added to the end of the `clipArr` until there are 6 clips in our array. We return `clipArr` to the calling section.

[role="curriculum-python"]
Then, how do we choose a single clip from the random `clipList`? We call `chooseClip`, passing it our random `clipList` as the first argument. The second argument decides what kind of clip the function will choose: one with high RMS_AMPLITUDE _and_ SPECTRAL_CENTROID values, or one with low values. Since there are only 2 choices, we pass it a 'True' value to mean high, and 'False' to mean low.

[role="curriculum-javascript"]
Then, how do we choose a single clip from the random `clipArr`? We call `chooseClip`, passing it our random `clipArr` as the first argument. The second argument decides what kind of clip the function will choose: one with high RMS_AMPLITUDE _and_ SPECTRAL_CENTROID values, or one with low values. Since there are only 2 choices, we pass it a 'true' value to mean high, and 'false' to mean low.

[role="curriculum-python"]
The conditional checks if we have chosen True or False (high or low). If we chose True, the code goes into the `if`, and if we chose False it goes into the `else`. Notice that these 2 blocks are almost the same, except all of the `>` become `<`. Inside of the conditionals there is a loop which compares the analysis values of every clip in the clipList, and finds either the highest (for True) or the lowest (for False). It only changes the `clip` variable when we find something better than what is currently stored in `clip`.

[role="curriculum-javascript"]
The conditional checks if we have chosen true or false (high or low). If we chose true, the code goes into the `if`, and if we chose false it goes into the `else`. Notice that these 2 blocks are almost the same, except all of the `>` become `<`. Inside of the conditionals there is a loop which compares the analysis values of every clip in the clipArr, and finds either the highest (for true) or the lowest (for false). It only changes the `clip` variable when we find something better than what is currently stored in `clip`.

[role="curriculum-python"]
The Boolean operator lets us combine conditions to choose a clip that has both the highest amplitude and spectral centroid in our clipList (or the lowest, if we've chosen False).

[role="curriculum-javascript"]
The Boolean operator lets us combine conditions to choose a clip that has both the highest amplitude and spectral centroid in our clipArr (or the lowest, if we've chosen false).

[role="curriculum-python"]
[source,python]
----
# Boolean Operators: Using Boolean operators to pick clips to use.

# Setup
from earsketch import *
setTempo(120)

# Music
def fillClipList(folder):
    clipList = []
    # Fill our clipList with 6 random files from a folder
    while len(clipList) < 6:
        randClip = selectRandomFile(folder)
        clipList = clipList + [randClip]
    return clipList

def chooseClip(clipList, chooseHigher):

    clip = clipList[0]  # Assign a first clip for comparison

    # Decide if we are looking for highest or lowest value (True picks higher, False picks lower)
    if chooseHigher:
        # Compare all clips in list with current clip, using 2 features. Start from 1 because we don't need to compare clipList[0] to itself
        for i in range(1, len(clipList)):
            val1 = analyze(clipList[i], RMS_AMPLITUDE)  # Analyze our clips
            val2 = analyze(clip, RMS_AMPLITUDE)
            val3 = analyze(clipList[i], SPECTRAL_CENTROID)
            val4 = analyze(clip, SPECTRAL_CENTROID)
            if (val1 > val2) and (val3 > val4):  # Pick current highest value
                clip = clipList[i]
    else:
        for i in range(1, len(clipList)):
            val1 = analyze(clipList[i], RMS_AMPLITUDE)
            val2 = analyze(clip, RMS_AMPLITUDE)
            val3 = analyze(clipList[i], SPECTRAL_CENTROID)
            val4 = analyze(clip, SPECTRAL_CENTROID)
            if (val1 < val2) and (val3 < val4):  # Pick current lowest value
                clip = clipList[i]
    return clip

def sectionA(start, end):
    measures = end - start

    # Fill a list of random clips for each instrument.
    leadClips = fillClipList(DUBSTEP_140_BPM__DUBLEAD)
    drumClips = fillClipList(DUBSTEP_140_BPM__DUBDRUM)
    bassClips = fillClipList(DUBSTEP_140_BPM__DUBSUBBASS)

    # Choose a clip from the random clipLists, with the lowest analysis values (False)
    lead = chooseClip(leadClips, False)
    drum = chooseClip(drumClips, False)
    bass = chooseClip(bassClips, False)

    # Add clips to the first half of section
    fitMedia(lead, 1, start, start + measures / 2.0)
    fitMedia(drum, 2, start, start + measures / 2.0)
    fitMedia(bass, 3, start, start + measures / 2.0)

    # Now, pick new clips with high values (True)
    lead = chooseClip(leadClips, True)
    drum = chooseClip(drumClips, True)
    bass = chooseClip(bassClips, True)

    # Add new clips to second half of section
    fitMedia(lead, 1, start + measures / 2.0, end)
    fitMedia(drum, 2, start + measures / 2.0, end)
    fitMedia(bass, 3, start + measures / 2.0, end)

    setEffect(3, VOLUME, GAIN, 0, start, 12, end)  # Make the bass louder
    setEffect(1, FILTER, FILTER_FREQ, 200, start, 20000, end)

def sectionB(start, end):
    leadClips = fillClipList(TRAP_SYNTH_LEAD)
    drumClips = fillClipList(TRAP_MAIN808_BEAT)
    bassClips = fillClipList(DUBSTEP_140_BPM__DUBBASSWOBBLE)

    # Choose clips with low analysis value (False)
    lead = chooseClip(leadClips, False)
    drum = chooseClip(drumClips, False)
    bass = chooseClip(bassClips, False)

    fitMedia(lead, 1, start, end)
    fitMedia(drum, 2, start, end)
    fitMedia(bass, 3, start, end)
    setEffect(3, VOLUME, GAIN, 0, start)  # Make the bass normal again
    setEffect(1, VOLUME, GAIN, 10, start)

# Call our sections with measure numbers
sectionA(1, 17)
sectionA(17, 33)
sectionB(33, 41)
sectionA(41, 57)
----



[role="curriculum-javascript"]
[source,javascript]
----
// Boolean Operators: Using Boolean operators to pick clips to use

// Setup
setTempo(120);

function fillClipArr(folder) {
    var clipArr = [];
    // Fill our clipArr with 6 random files from a folder
    while (clipArr.length < 6) {
        var randClip = selectRandomFile(folder);
        clipArr.push(randClip); // Add random clip to end of clipArr
    }

    return clipArr;
}

function chooseClip(clipArr, chooseHigher) {
    var clip = clipArr[0]; // Assign a first clip for comparison

    // Decide if we are looking for highest or lowest value (true picks higher, false picks lower)
    if (chooseHigher) {
        // Compare all clips in array with current clip, using 2 features. Start from 1 because we don't need to compare clipArr[0] to itself
        for (var i = 1; i < clipArr.length; i = i + 1) {
            var val1 = analyze(clipArr[i], RMS_AMPLITUDE); // Analyze our clips
            var val2 = analyze(clip, RMS_AMPLITUDE);
            var val3 = analyze(clipArr[i], SPECTRAL_CENTROID);
            var val4 = analyze(clip, SPECTRAL_CENTROID);
            if ((val1 > val2) && (val3 > val4)) { // Pick current highest value
                clip = clipArr[i];
            }
        }
    } else {
        for (var i = 1; i < clipArr.length; i = i + 1) {
            var val1 = analyze(clipArr[i], RMS_AMPLITUDE);
            var val2 = analyze(clip, RMS_AMPLITUDE);
            var val3 = analyze(clipArr[i], SPECTRAL_CENTROID);
            var val4 = analyze(clip, SPECTRAL_CENTROID);
            if ((val1 < val2) && (val3 < val4)) { // Pick current lowest value
                clip = clipArr[i];
            }
        }
    }

    return clip;
}

function sectionA(start, end) {
    var measures = end - start;

    // Fill an array of random clips for each instrument.
    var leadClips = fillClipArr(DUBSTEP_140_BPM__DUBLEAD);
    var drumClips = fillClipArr(DUBSTEP_140_BPM__DUBDRUM);
    var bassClips = fillClipArr(DUBSTEP_140_BPM__DUBSUBBASS);

    // Choose a clip from the random clipArr, with the lowest analysis values (false)
    var lead = chooseClip(leadClips, false);
    var drum = chooseClip(drumClips, false);
    var bass = chooseClip(bassClips, false);

    // Add clips to the first half of section
    fitMedia(lead, 1, start, start + measures / 2);
    fitMedia(drum, 2, start, start + measures / 2);
    fitMedia(bass, 3, start, start + measures / 2);

    // Now, pick new clips with high values (true)
    lead = chooseClip(leadClips, true);
    drum = chooseClip(drumClips, true);
    bass = chooseClip(bassClips, true);

    // Add new clips to second half of section
    fitMedia(lead, 1, start + measures / 2, end);
    fitMedia(drum, 2, start + measures / 2, end);
    fitMedia(bass, 3, start + measures / 2, end);

    setEffect(3, VOLUME, GAIN, 0, start, 12, end); // Make the bass louder
    setEffect(1, FILTER, FILTER_FREQ, 200, start, 20000, end);
}

function sectionB(start, end) {
    var leadClips = fillClipArr(TRAP_SYNTH_LEAD);
    var drumClips = fillClipArr(TRAP_MAIN808_BEAT);
    var bassClips = fillClipArr(DUBSTEP_140_BPM__DUBBASSWOBBLE);

    // Choose clips with low analysis value (false)
    var lead = chooseClip(leadClips, false);
    var drum = chooseClip(drumClips, false);
    var bass = chooseClip(bassClips, false);

    fitMedia(lead, 1, start, end);
    fitMedia(drum, 2, start, end);
    fitMedia(bass, 3, start, end);
    setEffect(3, VOLUME, GAIN, 0, start); // Make the bass normal again
    setEffect(1, VOLUME, GAIN, 10, start);
}

// Call our sections with measure numbers
sectionA(1, 17);
sectionA(17, 33);
sectionB(33, 41);
sectionA(41, 57);
----

[[chapter22summary]]
=== Chapter 22 Summary
* Music Information Retrieval (MIR) is a field in music technology that includes ways for a computer to listen to music.
* Any sound can be analyzed with MIR and the results can be used to change the output.
* `analyze()` can be used to extract the level of brightness vs darkness with SPECTRAL_CENTROID and the volume RMS_AMPLITUDE
* Analysis of tracks is best used with conditional statements to make changes based on the result of the function
* Analysis can be done over a whole track, or just part of a track by using `analyzeTrackForTime()`


[[chapter-questions]]
=== Questions

[question]
--
Select the statement below that is not true:
[answers]
* `analyze()` requires three arguments
* `SPECTRAL_CENTROID` is a feature that corresponds to how bright/dark a sound is
* `analyzeTrackForTime()` can use the features `SPECTRAL_CENTROID` and `RMS_AMPLITUDE`
* Analysis of audio is best combined with conditional statements
--

[question]
--
Assuming `trackName` is a variable assigned to a valid clip, The output of `analyze(trackName, RMS_AMPLITUDE)` :
[answers]
* Will always be a float between 0 and 1.
* Can be any number above 0.
* Will be a value showing the pitch of trackName
* Will return an error message
--
